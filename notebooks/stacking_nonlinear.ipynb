{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:55:23.394186Z",
     "start_time": "2021-07-28T23:55:21.989991Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_PATH = Path(\"/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize\")\n",
    "OUTPUT_PATH = Path(\"/mnt/storage_dimm2/kaggle_output/commonlitreadabilityprize\")\n",
    "\n",
    "torch.manual_seed(48)\n",
    "np.random.seed(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:55:23.398753Z",
     "start_time": "2021-07-28T23:55:23.395567Z"
    }
   },
   "outputs": [],
   "source": [
    "model_folders = [\n",
    "    \"20210614-203831\",\n",
    "    \"20210615-094729\",\n",
    "    \"20210616-003038\",\n",
    "    \"20210616-041221\",\n",
    "    \"20210616-132341\",\n",
    "    \"20210617-135233\",\n",
    "    \"20210618-183719\",\n",
    "    \"20210618-223208\",\n",
    "    \"20210619-004022\",\n",
    "    \"20210619-035747\",\n",
    "    \"20210619-064351\",\n",
    "    \"20210619-093050\",\n",
    "    \"20210623-201514\",\n",
    "    \"20210623-232231\",\n",
    "    \"20210624-012102\",\n",
    "    \"20210624-015812\",\n",
    "    \"20210624-101855\",\n",
    "    \"20210624-044356\",\n",
    "    \"20210624-113506\",\n",
    "    \"20210624-150250\",\n",
    "    \"20210627-105133\",\n",
    "    \"20210627-152616\",\n",
    "    \"20210627-105144\",\n",
    "    \"20210627-151904\",\n",
    "    \"20210628-045559\",\n",
    "    \"20210628-085322\",\n",
    "    \"20210627-213946\",\n",
    "    \"20210628-031447\",\n",
    "    \"20210628-114738\",\n",
    "    \"20210628-145921\",\n",
    "    \"20210628-212819\",\n",
    "    \"20210629-012726\",\n",
    "    \"20210629-035901\",\n",
    "    \"20210629-163239\",\n",
    "    \"20210705-162253\",\n",
    "    \"20210710-124531\",\n",
    "    \"20210710-173710\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:55:23.406186Z",
     "start_time": "2021-07-28T23:55:23.400029Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_oof_df(folders=model_folders):\n",
    "    dataset_paths = [OUTPUT_PATH / f for f in folders]\n",
    "    mpaths, oof_paths = [], []\n",
    "    for p in dataset_paths:\n",
    "        mpaths.append(sorted(list(p.glob(f\"*/*/*.ckpt\"))))\n",
    "        oof_paths.extend(sorted(list(p.glob(f\"*.csv\"))))\n",
    "\n",
    "    oofs = pd.read_csv(\n",
    "        INPUT_PATH / \"train.csv\", usecols=[\"id\", \"target\", \"standard_error\"]\n",
    "    ).sort_values(by=\"id\")\n",
    "    for i, p in enumerate(oof_paths):\n",
    "        x = pd.read_csv(p).sort_values(by=\"id\")\n",
    "        oofs[p.parent.name] = x[\"prediction\"].values\n",
    "\n",
    "    return oofs.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def create_folds(data, n_splits, random_state=None):\n",
    "    # we create a new column called fold and fill it with -1\n",
    "    data[\"fold\"] = -1\n",
    "\n",
    "    # the next step is to randomize the rows of the data\n",
    "    data = data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # calculate number of bins by Sturge's rule\n",
    "    # I take the floor of the value, you can also\n",
    "    # just round it\n",
    "    num_bins = int(np.floor(1 + np.log2(len(data))))\n",
    "\n",
    "    # bin targets\n",
    "    data.loc[:, \"bins\"] = pd.cut(data[\"target\"], bins=num_bins, labels=False)\n",
    "\n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # fill the new kfold column\n",
    "    # note that, instead of targets, we use bins!\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n",
    "        data.loc[v_, \"fold\"] = f\n",
    "\n",
    "    # drop the bins column\n",
    "    data = data.drop(\"bins\", axis=1)\n",
    "\n",
    "    # return dataframe with folds\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:55:24.405444Z",
     "start_time": "2021-07-28T23:55:23.407331Z"
    }
   },
   "outputs": [],
   "source": [
    "oofs = build_oof_df()\n",
    "oofs = create_folds(oofs, 5, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:55:24.421967Z",
     "start_time": "2021-07-28T23:55:24.406880Z"
    }
   },
   "outputs": [],
   "source": [
    "oofs[\"std_dev\"] = oofs[model_folders].std(1)\n",
    "oofs[\"mean\"] = oofs[model_folders].mean(1)\n",
    "oofs[\"min\"] = oofs[model_folders].min(1)\n",
    "oofs[\"max\"] = oofs[model_folders].max(1)\n",
    "oofs[\"range\"] = oofs[model_folders].max(1) - oofs[model_folders].min(1)\n",
    "\n",
    "stat_feats = [\"std_dev\", \"min\", \"max\", \"range\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:55:24.498799Z",
     "start_time": "2021-07-28T23:55:24.423404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 RMSE: 0.45144\n",
      "Fold 1 RMSE: 0.43806\n",
      "Fold 2 RMSE: 0.42641\n",
      "Fold 3 RMSE: 0.46526\n",
      "Fold 4 RMSE: 0.43669\n",
      "Mean: 0.44357\n"
     ]
    }
   ],
   "source": [
    "fold_scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    trn_df = oofs.query(f\"fold != {fold}\")\n",
    "    val_df = oofs.query(f\"fold == {fold}\")\n",
    "#     trn_df = oofs_trfm.query(f\"fold != {fold}\")\n",
    "#     val_df = oofs_trfm.query(f\"fold == {fold}\")\n",
    "\n",
    "    train_X = torch.tensor(trn_df[model_folders].values, dtype=torch.float32)\n",
    "    train_y = torch.tensor(trn_df[\"target\"].values, dtype=torch.float32).view(-1, 1)\n",
    "    valid_X = torch.tensor(val_df[model_folders].values, dtype=torch.float32)\n",
    "    valid_y = torch.tensor(val_df[\"target\"].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    W = torch.linalg.lstsq(train_X, train_y).solution\n",
    "    y_pred = valid_X @ W\n",
    "    rmse = torch.sqrt(torch.nn.functional.mse_loss(y_pred, valid_y)).numpy()\n",
    "\n",
    "    print(f\"Fold {fold} RMSE: {rmse:0.5f}\")\n",
    "    fold_scores.append(rmse)\n",
    "\n",
    "print(f\"Mean: {np.mean(fold_scores):0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:55:24.503490Z",
     "start_time": "2021-07-28T23:55:24.500382Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden=64):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_inputs, n_hidden, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "        )\n",
    "#         self.net = nn.Linear(n_inputs, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:57:53.699532Z",
     "start_time": "2021-07-28T23:55:24.504562Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 best loss 0.45220 at epoch 11\n",
      "Fold 1 best loss 0.44303 at epoch 10\n",
      "Fold 2 best loss 0.42409 at epoch 9\n",
      "Fold 3 best loss 0.46575 at epoch 12\n",
      "Fold 4 best loss 0.44276 at epoch 6\n",
      "Mean: 0.44557\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "fold_scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    trn_df = oofs.query(f\"fold != {fold}\")\n",
    "    val_df = oofs.query(f\"fold == {fold}\")\n",
    "\n",
    "    train_X = torch.tensor(trn_df[model_folders + stat_feats].values, dtype=torch.float32)\n",
    "    train_y = torch.tensor(trn_df[\"target\"].values, dtype=torch.float32).view(-1, 1)\n",
    "    valid_X = torch.tensor(val_df[model_folders + stat_feats].values, dtype=torch.float32)\n",
    "    valid_y = torch.tensor(val_df[\"target\"].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    train_dataset = TensorDataset(train_X, train_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = Net(train_X.shape[1])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    val_loss_curve = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_loss = []\n",
    "        for features, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(features)\n",
    "            loss = loss_fn(y_pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.detach().numpy())\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        y_pred = model(valid_X)\n",
    "        loss = loss_fn(y_pred, valid_y)\n",
    "        valid_loss = loss.detach().numpy()\n",
    "        val_loss_curve.append(np.sqrt(valid_loss))\n",
    "\n",
    "#         print(\n",
    "#             f\"Fold: {fold}, Epoch: {epoch}, \"\n",
    "#             f\"Train loss: {np.sqrt(np.mean(train_loss)):0.5f}, \"\n",
    "#             f\"Valid loss: {np.sqrt(np.mean(valid_loss)):0.5f}\",\n",
    "#         )\n",
    "\n",
    "    print(\n",
    "        f\"Fold {fold} best loss {np.min(val_loss_curve):0.5f} at epoch {np.argmin(val_loss_curve)}\"\n",
    "    )\n",
    "    fold_scores.append(np.min(val_loss_curve))\n",
    "\n",
    "print(f\"Mean: {np.mean(fold_scores):0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:57:53.703184Z",
     "start_time": "2021-07-28T23:57:53.701109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mean: 0.44111 - Linear only\n",
    "# Mean: 0.44423 - 2 layers\n",
    "# Mean: 0.44539 - 3 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:57:53.808574Z",
     "start_time": "2021-07-28T23:57:53.704451Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:58:00.912432Z",
     "start_time": "2021-07-28T23:57:53.810051Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.77438\tvalid-rmse:1.76026\n",
      "[10]\ttrain-rmse:1.61744\tvalid-rmse:1.60484\n",
      "[20]\ttrain-rmse:1.47635\tvalid-rmse:1.46531\n",
      "[30]\ttrain-rmse:1.34969\tvalid-rmse:1.33990\n",
      "[40]\ttrain-rmse:1.23604\tvalid-rmse:1.22753\n",
      "[50]\ttrain-rmse:1.13427\tvalid-rmse:1.12719\n",
      "[60]\ttrain-rmse:1.04335\tvalid-rmse:1.03753\n",
      "[70]\ttrain-rmse:0.96230\tvalid-rmse:0.95786\n",
      "[80]\ttrain-rmse:0.89026\tvalid-rmse:0.88737\n",
      "[90]\ttrain-rmse:0.82639\tvalid-rmse:0.82532\n",
      "[100]\ttrain-rmse:0.76996\tvalid-rmse:0.77085\n",
      "[110]\ttrain-rmse:0.72029\tvalid-rmse:0.72312\n",
      "[120]\ttrain-rmse:0.67675\tvalid-rmse:0.68167\n",
      "[130]\ttrain-rmse:0.63872\tvalid-rmse:0.64563\n",
      "[140]\ttrain-rmse:0.60567\tvalid-rmse:0.61469\n",
      "[150]\ttrain-rmse:0.57705\tvalid-rmse:0.58822\n",
      "[160]\ttrain-rmse:0.55236\tvalid-rmse:0.56564\n",
      "[170]\ttrain-rmse:0.53114\tvalid-rmse:0.54651\n",
      "[180]\ttrain-rmse:0.51299\tvalid-rmse:0.53031\n",
      "[190]\ttrain-rmse:0.49746\tvalid-rmse:0.51682\n",
      "[200]\ttrain-rmse:0.48426\tvalid-rmse:0.50554\n",
      "[210]\ttrain-rmse:0.47303\tvalid-rmse:0.49606\n",
      "[220]\ttrain-rmse:0.46345\tvalid-rmse:0.48813\n",
      "[230]\ttrain-rmse:0.45530\tvalid-rmse:0.48167\n",
      "[240]\ttrain-rmse:0.44838\tvalid-rmse:0.47637\n",
      "[250]\ttrain-rmse:0.44247\tvalid-rmse:0.47191\n",
      "[260]\ttrain-rmse:0.43738\tvalid-rmse:0.46842\n",
      "[270]\ttrain-rmse:0.43306\tvalid-rmse:0.46562\n",
      "[280]\ttrain-rmse:0.42927\tvalid-rmse:0.46325\n",
      "[290]\ttrain-rmse:0.42596\tvalid-rmse:0.46138\n",
      "[300]\ttrain-rmse:0.42310\tvalid-rmse:0.45989\n",
      "[310]\ttrain-rmse:0.42055\tvalid-rmse:0.45860\n",
      "[320]\ttrain-rmse:0.41828\tvalid-rmse:0.45760\n",
      "[330]\ttrain-rmse:0.41625\tvalid-rmse:0.45679\n",
      "[340]\ttrain-rmse:0.41447\tvalid-rmse:0.45595\n",
      "[350]\ttrain-rmse:0.41288\tvalid-rmse:0.45542\n",
      "[360]\ttrain-rmse:0.41141\tvalid-rmse:0.45509\n",
      "[370]\ttrain-rmse:0.41006\tvalid-rmse:0.45476\n",
      "[380]\ttrain-rmse:0.40882\tvalid-rmse:0.45450\n",
      "[390]\ttrain-rmse:0.40765\tvalid-rmse:0.45437\n",
      "[400]\ttrain-rmse:0.40643\tvalid-rmse:0.45429\n",
      "[410]\ttrain-rmse:0.40532\tvalid-rmse:0.45428\n",
      "[420]\ttrain-rmse:0.40424\tvalid-rmse:0.45422\n",
      "[430]\ttrain-rmse:0.40317\tvalid-rmse:0.45417\n",
      "[440]\ttrain-rmse:0.40215\tvalid-rmse:0.45408\n",
      "[450]\ttrain-rmse:0.40122\tvalid-rmse:0.45408\n",
      "[460]\ttrain-rmse:0.40035\tvalid-rmse:0.45407\n",
      "[470]\ttrain-rmse:0.39951\tvalid-rmse:0.45394\n",
      "[480]\ttrain-rmse:0.39873\tvalid-rmse:0.45396\n",
      "[490]\ttrain-rmse:0.39794\tvalid-rmse:0.45397\n",
      "[500]\ttrain-rmse:0.39717\tvalid-rmse:0.45391\n",
      "[510]\ttrain-rmse:0.39657\tvalid-rmse:0.45401\n",
      "[520]\ttrain-rmse:0.39588\tvalid-rmse:0.45411\n",
      "[530]\ttrain-rmse:0.39526\tvalid-rmse:0.45419\n",
      "[540]\ttrain-rmse:0.39463\tvalid-rmse:0.45423\n",
      "[547]\ttrain-rmse:0.39421\tvalid-rmse:0.45430\n",
      "Fold 0 RMSE: 0.45430\n",
      "[0]\ttrain-rmse:1.77241\tvalid-rmse:1.76828\n",
      "[10]\ttrain-rmse:1.61577\tvalid-rmse:1.61337\n",
      "[20]\ttrain-rmse:1.47497\tvalid-rmse:1.47441\n",
      "[30]\ttrain-rmse:1.34855\tvalid-rmse:1.35023\n",
      "[40]\ttrain-rmse:1.23519\tvalid-rmse:1.23890\n",
      "[50]\ttrain-rmse:1.13366\tvalid-rmse:1.13939\n",
      "[60]\ttrain-rmse:1.04296\tvalid-rmse:1.05089\n",
      "[70]\ttrain-rmse:0.96214\tvalid-rmse:0.97214\n",
      "[80]\ttrain-rmse:0.89031\tvalid-rmse:0.90258\n",
      "[90]\ttrain-rmse:0.82662\tvalid-rmse:0.84089\n",
      "[100]\ttrain-rmse:0.77039\tvalid-rmse:0.78629\n",
      "[110]\ttrain-rmse:0.72088\tvalid-rmse:0.73854\n",
      "[120]\ttrain-rmse:0.67748\tvalid-rmse:0.69668\n",
      "[130]\ttrain-rmse:0.63961\tvalid-rmse:0.66030\n",
      "[140]\ttrain-rmse:0.60666\tvalid-rmse:0.62879\n",
      "[150]\ttrain-rmse:0.57815\tvalid-rmse:0.60152\n",
      "[160]\ttrain-rmse:0.55358\tvalid-rmse:0.57809\n",
      "[170]\ttrain-rmse:0.53249\tvalid-rmse:0.55812\n",
      "[180]\ttrain-rmse:0.51445\tvalid-rmse:0.54130\n",
      "[190]\ttrain-rmse:0.49906\tvalid-rmse:0.52700\n",
      "[200]\ttrain-rmse:0.48593\tvalid-rmse:0.51486\n",
      "[210]\ttrain-rmse:0.47470\tvalid-rmse:0.50451\n",
      "[220]\ttrain-rmse:0.46513\tvalid-rmse:0.49600\n",
      "[230]\ttrain-rmse:0.45696\tvalid-rmse:0.48897\n",
      "[240]\ttrain-rmse:0.44998\tvalid-rmse:0.48298\n",
      "[250]\ttrain-rmse:0.44405\tvalid-rmse:0.47777\n",
      "[260]\ttrain-rmse:0.43899\tvalid-rmse:0.47347\n",
      "[270]\ttrain-rmse:0.43464\tvalid-rmse:0.46997\n",
      "[280]\ttrain-rmse:0.43091\tvalid-rmse:0.46697\n",
      "[290]\ttrain-rmse:0.42773\tvalid-rmse:0.46462\n",
      "[300]\ttrain-rmse:0.42489\tvalid-rmse:0.46247\n",
      "[310]\ttrain-rmse:0.42242\tvalid-rmse:0.46086\n",
      "[320]\ttrain-rmse:0.42027\tvalid-rmse:0.45939\n",
      "[330]\ttrain-rmse:0.41838\tvalid-rmse:0.45805\n",
      "[340]\ttrain-rmse:0.41663\tvalid-rmse:0.45683\n",
      "[350]\ttrain-rmse:0.41505\tvalid-rmse:0.45591\n",
      "[360]\ttrain-rmse:0.41352\tvalid-rmse:0.45511\n",
      "[370]\ttrain-rmse:0.41214\tvalid-rmse:0.45452\n",
      "[380]\ttrain-rmse:0.41088\tvalid-rmse:0.45398\n",
      "[390]\ttrain-rmse:0.40973\tvalid-rmse:0.45367\n",
      "[400]\ttrain-rmse:0.40860\tvalid-rmse:0.45348\n",
      "[410]\ttrain-rmse:0.40755\tvalid-rmse:0.45307\n",
      "[420]\ttrain-rmse:0.40648\tvalid-rmse:0.45292\n",
      "[430]\ttrain-rmse:0.40560\tvalid-rmse:0.45259\n",
      "[440]\ttrain-rmse:0.40468\tvalid-rmse:0.45248\n",
      "[450]\ttrain-rmse:0.40388\tvalid-rmse:0.45229\n",
      "[460]\ttrain-rmse:0.40308\tvalid-rmse:0.45201\n",
      "[470]\ttrain-rmse:0.40230\tvalid-rmse:0.45199\n",
      "[480]\ttrain-rmse:0.40150\tvalid-rmse:0.45186\n",
      "[490]\ttrain-rmse:0.40086\tvalid-rmse:0.45180\n",
      "[500]\ttrain-rmse:0.40006\tvalid-rmse:0.45154\n",
      "[510]\ttrain-rmse:0.39938\tvalid-rmse:0.45147\n",
      "[520]\ttrain-rmse:0.39866\tvalid-rmse:0.45143\n",
      "[530]\ttrain-rmse:0.39799\tvalid-rmse:0.45131\n",
      "[540]\ttrain-rmse:0.39728\tvalid-rmse:0.45122\n",
      "[550]\ttrain-rmse:0.39671\tvalid-rmse:0.45116\n",
      "[560]\ttrain-rmse:0.39607\tvalid-rmse:0.45103\n",
      "[570]\ttrain-rmse:0.39542\tvalid-rmse:0.45094\n",
      "[580]\ttrain-rmse:0.39475\tvalid-rmse:0.45090\n",
      "[590]\ttrain-rmse:0.39427\tvalid-rmse:0.45087\n",
      "[600]\ttrain-rmse:0.39365\tvalid-rmse:0.45078\n",
      "[610]\ttrain-rmse:0.39318\tvalid-rmse:0.45083\n",
      "[620]\ttrain-rmse:0.39258\tvalid-rmse:0.45082\n",
      "[630]\ttrain-rmse:0.39193\tvalid-rmse:0.45080\n",
      "[640]\ttrain-rmse:0.39148\tvalid-rmse:0.45073\n",
      "[650]\ttrain-rmse:0.39107\tvalid-rmse:0.45075\n",
      "[660]\ttrain-rmse:0.39058\tvalid-rmse:0.45075\n",
      "[670]\ttrain-rmse:0.39018\tvalid-rmse:0.45079\n",
      "[680]\ttrain-rmse:0.38973\tvalid-rmse:0.45079\n",
      "[690]\ttrain-rmse:0.38926\tvalid-rmse:0.45077\n",
      "[700]\ttrain-rmse:0.38883\tvalid-rmse:0.45072\n",
      "[705]\ttrain-rmse:0.38849\tvalid-rmse:0.45075\n",
      "Fold 1 RMSE: 0.45076\n",
      "[0]\ttrain-rmse:1.76886\tvalid-rmse:1.78245\n",
      "[10]\ttrain-rmse:1.61271\tvalid-rmse:1.62454\n",
      "[20]\ttrain-rmse:1.47229\tvalid-rmse:1.48248\n",
      "[30]\ttrain-rmse:1.34619\tvalid-rmse:1.35506\n",
      "[40]\ttrain-rmse:1.23314\tvalid-rmse:1.24097\n",
      "[50]\ttrain-rmse:1.13193\tvalid-rmse:1.13901\n",
      "[60]\ttrain-rmse:1.04151\tvalid-rmse:1.04820\n",
      "[70]\ttrain-rmse:0.96096\tvalid-rmse:0.96741\n",
      "[80]\ttrain-rmse:0.88941\tvalid-rmse:0.89566\n",
      "[90]\ttrain-rmse:0.82602\tvalid-rmse:0.83225\n",
      "[100]\ttrain-rmse:0.77000\tvalid-rmse:0.77642\n",
      "[110]\ttrain-rmse:0.72074\tvalid-rmse:0.72734\n",
      "[120]\ttrain-rmse:0.67754\tvalid-rmse:0.68434\n",
      "[130]\ttrain-rmse:0.63986\tvalid-rmse:0.64698\n",
      "[140]\ttrain-rmse:0.60712\tvalid-rmse:0.61456\n",
      "[150]\ttrain-rmse:0.57881\tvalid-rmse:0.58674\n",
      "[160]\ttrain-rmse:0.55443\tvalid-rmse:0.56280\n",
      "[170]\ttrain-rmse:0.53350\tvalid-rmse:0.54245\n",
      "[180]\ttrain-rmse:0.51555\tvalid-rmse:0.52516\n",
      "[190]\ttrain-rmse:0.50024\tvalid-rmse:0.51062\n",
      "[200]\ttrain-rmse:0.48718\tvalid-rmse:0.49838\n",
      "[210]\ttrain-rmse:0.47608\tvalid-rmse:0.48800\n",
      "[220]\ttrain-rmse:0.46665\tvalid-rmse:0.47943\n",
      "[230]\ttrain-rmse:0.45860\tvalid-rmse:0.47233\n",
      "[240]\ttrain-rmse:0.45176\tvalid-rmse:0.46646\n",
      "[250]\ttrain-rmse:0.44589\tvalid-rmse:0.46171\n",
      "[260]\ttrain-rmse:0.44087\tvalid-rmse:0.45774\n",
      "[270]\ttrain-rmse:0.43654\tvalid-rmse:0.45430\n",
      "[280]\ttrain-rmse:0.43277\tvalid-rmse:0.45162\n",
      "[290]\ttrain-rmse:0.42951\tvalid-rmse:0.44945\n",
      "[300]\ttrain-rmse:0.42667\tvalid-rmse:0.44759\n",
      "[310]\ttrain-rmse:0.42420\tvalid-rmse:0.44609\n",
      "[320]\ttrain-rmse:0.42196\tvalid-rmse:0.44499\n",
      "[330]\ttrain-rmse:0.41998\tvalid-rmse:0.44410\n",
      "[340]\ttrain-rmse:0.41817\tvalid-rmse:0.44336\n",
      "[350]\ttrain-rmse:0.41652\tvalid-rmse:0.44270\n",
      "[360]\ttrain-rmse:0.41506\tvalid-rmse:0.44227\n",
      "[370]\ttrain-rmse:0.41377\tvalid-rmse:0.44184\n",
      "[380]\ttrain-rmse:0.41257\tvalid-rmse:0.44145\n",
      "[390]\ttrain-rmse:0.41136\tvalid-rmse:0.44123\n",
      "[400]\ttrain-rmse:0.41018\tvalid-rmse:0.44098\n",
      "[410]\ttrain-rmse:0.40911\tvalid-rmse:0.44081\n",
      "[420]\ttrain-rmse:0.40806\tvalid-rmse:0.44067\n",
      "[430]\ttrain-rmse:0.40702\tvalid-rmse:0.44036\n",
      "[440]\ttrain-rmse:0.40595\tvalid-rmse:0.44015\n",
      "[450]\ttrain-rmse:0.40497\tvalid-rmse:0.44000\n",
      "[460]\ttrain-rmse:0.40414\tvalid-rmse:0.43987\n",
      "[470]\ttrain-rmse:0.40336\tvalid-rmse:0.43985\n",
      "[480]\ttrain-rmse:0.40252\tvalid-rmse:0.43968\n",
      "[490]\ttrain-rmse:0.40184\tvalid-rmse:0.43969\n",
      "[500]\ttrain-rmse:0.40112\tvalid-rmse:0.43962\n",
      "[510]\ttrain-rmse:0.40045\tvalid-rmse:0.43955\n",
      "[520]\ttrain-rmse:0.39977\tvalid-rmse:0.43954\n",
      "[530]\ttrain-rmse:0.39913\tvalid-rmse:0.43942\n",
      "[540]\ttrain-rmse:0.39854\tvalid-rmse:0.43947\n",
      "[550]\ttrain-rmse:0.39803\tvalid-rmse:0.43953\n",
      "[560]\ttrain-rmse:0.39743\tvalid-rmse:0.43952\n",
      "[570]\ttrain-rmse:0.39685\tvalid-rmse:0.43946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[580]\ttrain-rmse:0.39633\tvalid-rmse:0.43950\n",
      "[582]\ttrain-rmse:0.39625\tvalid-rmse:0.43951\n",
      "Fold 2 RMSE: 0.43951\n",
      "[0]\ttrain-rmse:1.77094\tvalid-rmse:1.77404\n",
      "[10]\ttrain-rmse:1.61425\tvalid-rmse:1.61710\n",
      "[20]\ttrain-rmse:1.47340\tvalid-rmse:1.47571\n",
      "[30]\ttrain-rmse:1.34677\tvalid-rmse:1.34945\n",
      "[40]\ttrain-rmse:1.23319\tvalid-rmse:1.23634\n",
      "[50]\ttrain-rmse:1.13152\tvalid-rmse:1.13540\n",
      "[60]\ttrain-rmse:1.04064\tvalid-rmse:1.04564\n",
      "[70]\ttrain-rmse:0.95961\tvalid-rmse:0.96584\n",
      "[80]\ttrain-rmse:0.88757\tvalid-rmse:0.89523\n",
      "[90]\ttrain-rmse:0.82370\tvalid-rmse:0.83316\n",
      "[100]\ttrain-rmse:0.76723\tvalid-rmse:0.77882\n",
      "[110]\ttrain-rmse:0.71751\tvalid-rmse:0.73134\n",
      "[120]\ttrain-rmse:0.67391\tvalid-rmse:0.69005\n",
      "[130]\ttrain-rmse:0.63582\tvalid-rmse:0.65453\n",
      "[140]\ttrain-rmse:0.60270\tvalid-rmse:0.62390\n",
      "[150]\ttrain-rmse:0.57401\tvalid-rmse:0.59782\n",
      "[160]\ttrain-rmse:0.54928\tvalid-rmse:0.57569\n",
      "[170]\ttrain-rmse:0.52804\tvalid-rmse:0.55712\n",
      "[180]\ttrain-rmse:0.50987\tvalid-rmse:0.54156\n",
      "[190]\ttrain-rmse:0.49434\tvalid-rmse:0.52863\n",
      "[200]\ttrain-rmse:0.48113\tvalid-rmse:0.51801\n",
      "[210]\ttrain-rmse:0.46990\tvalid-rmse:0.50907\n",
      "[220]\ttrain-rmse:0.46033\tvalid-rmse:0.50183\n",
      "[230]\ttrain-rmse:0.45219\tvalid-rmse:0.49592\n",
      "[240]\ttrain-rmse:0.44527\tvalid-rmse:0.49101\n",
      "[250]\ttrain-rmse:0.43937\tvalid-rmse:0.48698\n",
      "[260]\ttrain-rmse:0.43434\tvalid-rmse:0.48375\n",
      "[270]\ttrain-rmse:0.43001\tvalid-rmse:0.48122\n",
      "[280]\ttrain-rmse:0.42628\tvalid-rmse:0.47918\n",
      "[290]\ttrain-rmse:0.42302\tvalid-rmse:0.47762\n",
      "[300]\ttrain-rmse:0.42014\tvalid-rmse:0.47621\n",
      "[310]\ttrain-rmse:0.41760\tvalid-rmse:0.47517\n",
      "[320]\ttrain-rmse:0.41538\tvalid-rmse:0.47419\n",
      "[330]\ttrain-rmse:0.41339\tvalid-rmse:0.47353\n",
      "[340]\ttrain-rmse:0.41165\tvalid-rmse:0.47292\n",
      "[350]\ttrain-rmse:0.41000\tvalid-rmse:0.47237\n",
      "[360]\ttrain-rmse:0.40853\tvalid-rmse:0.47208\n",
      "[370]\ttrain-rmse:0.40717\tvalid-rmse:0.47190\n",
      "[380]\ttrain-rmse:0.40591\tvalid-rmse:0.47176\n",
      "[390]\ttrain-rmse:0.40475\tvalid-rmse:0.47165\n",
      "[400]\ttrain-rmse:0.40364\tvalid-rmse:0.47152\n",
      "[410]\ttrain-rmse:0.40255\tvalid-rmse:0.47143\n",
      "[420]\ttrain-rmse:0.40148\tvalid-rmse:0.47141\n",
      "[430]\ttrain-rmse:0.40037\tvalid-rmse:0.47134\n",
      "[440]\ttrain-rmse:0.39942\tvalid-rmse:0.47129\n",
      "[450]\ttrain-rmse:0.39848\tvalid-rmse:0.47138\n",
      "[460]\ttrain-rmse:0.39760\tvalid-rmse:0.47146\n",
      "[470]\ttrain-rmse:0.39680\tvalid-rmse:0.47143\n",
      "[480]\ttrain-rmse:0.39601\tvalid-rmse:0.47161\n",
      "[488]\ttrain-rmse:0.39542\tvalid-rmse:0.47162\n",
      "Fold 3 RMSE: 0.47157\n",
      "[0]\ttrain-rmse:1.77124\tvalid-rmse:1.77298\n",
      "[10]\ttrain-rmse:1.61466\tvalid-rmse:1.61840\n",
      "[20]\ttrain-rmse:1.47390\tvalid-rmse:1.47915\n",
      "[30]\ttrain-rmse:1.34746\tvalid-rmse:1.35462\n",
      "[40]\ttrain-rmse:1.23411\tvalid-rmse:1.24264\n",
      "[50]\ttrain-rmse:1.13263\tvalid-rmse:1.14273\n",
      "[60]\ttrain-rmse:1.04197\tvalid-rmse:1.05399\n",
      "[70]\ttrain-rmse:0.96115\tvalid-rmse:0.97500\n",
      "[80]\ttrain-rmse:0.88930\tvalid-rmse:0.90477\n",
      "[90]\ttrain-rmse:0.82567\tvalid-rmse:0.84282\n",
      "[100]\ttrain-rmse:0.76945\tvalid-rmse:0.78824\n",
      "[110]\ttrain-rmse:0.71997\tvalid-rmse:0.74033\n",
      "[120]\ttrain-rmse:0.67660\tvalid-rmse:0.69815\n",
      "[130]\ttrain-rmse:0.63872\tvalid-rmse:0.66150\n",
      "[140]\ttrain-rmse:0.60579\tvalid-rmse:0.62981\n",
      "[150]\ttrain-rmse:0.57730\tvalid-rmse:0.60236\n",
      "[160]\ttrain-rmse:0.55274\tvalid-rmse:0.57896\n",
      "[170]\ttrain-rmse:0.53168\tvalid-rmse:0.55884\n",
      "[180]\ttrain-rmse:0.51369\tvalid-rmse:0.54174\n",
      "[190]\ttrain-rmse:0.49833\tvalid-rmse:0.52716\n",
      "[200]\ttrain-rmse:0.48525\tvalid-rmse:0.51488\n",
      "[210]\ttrain-rmse:0.47406\tvalid-rmse:0.50463\n",
      "[220]\ttrain-rmse:0.46454\tvalid-rmse:0.49604\n",
      "[230]\ttrain-rmse:0.45642\tvalid-rmse:0.48891\n",
      "[240]\ttrain-rmse:0.44955\tvalid-rmse:0.48292\n",
      "[250]\ttrain-rmse:0.44365\tvalid-rmse:0.47782\n",
      "[260]\ttrain-rmse:0.43861\tvalid-rmse:0.47364\n",
      "[270]\ttrain-rmse:0.43428\tvalid-rmse:0.47014\n",
      "[280]\ttrain-rmse:0.43055\tvalid-rmse:0.46733\n",
      "[290]\ttrain-rmse:0.42738\tvalid-rmse:0.46490\n",
      "[300]\ttrain-rmse:0.42457\tvalid-rmse:0.46289\n",
      "[310]\ttrain-rmse:0.42220\tvalid-rmse:0.46123\n",
      "[320]\ttrain-rmse:0.42007\tvalid-rmse:0.45969\n",
      "[330]\ttrain-rmse:0.41816\tvalid-rmse:0.45836\n",
      "[340]\ttrain-rmse:0.41643\tvalid-rmse:0.45735\n",
      "[350]\ttrain-rmse:0.41483\tvalid-rmse:0.45641\n",
      "[360]\ttrain-rmse:0.41330\tvalid-rmse:0.45579\n",
      "[370]\ttrain-rmse:0.41192\tvalid-rmse:0.45523\n",
      "[380]\ttrain-rmse:0.41060\tvalid-rmse:0.45472\n",
      "[390]\ttrain-rmse:0.40932\tvalid-rmse:0.45413\n",
      "[400]\ttrain-rmse:0.40812\tvalid-rmse:0.45371\n",
      "[410]\ttrain-rmse:0.40700\tvalid-rmse:0.45335\n",
      "[420]\ttrain-rmse:0.40597\tvalid-rmse:0.45300\n",
      "[430]\ttrain-rmse:0.40493\tvalid-rmse:0.45276\n",
      "[440]\ttrain-rmse:0.40390\tvalid-rmse:0.45258\n",
      "[450]\ttrain-rmse:0.40301\tvalid-rmse:0.45243\n",
      "[460]\ttrain-rmse:0.40219\tvalid-rmse:0.45228\n",
      "[470]\ttrain-rmse:0.40147\tvalid-rmse:0.45209\n",
      "[480]\ttrain-rmse:0.40074\tvalid-rmse:0.45200\n",
      "[490]\ttrain-rmse:0.40002\tvalid-rmse:0.45199\n",
      "[500]\ttrain-rmse:0.39929\tvalid-rmse:0.45188\n",
      "[510]\ttrain-rmse:0.39870\tvalid-rmse:0.45183\n",
      "[520]\ttrain-rmse:0.39803\tvalid-rmse:0.45183\n",
      "[530]\ttrain-rmse:0.39745\tvalid-rmse:0.45174\n",
      "[540]\ttrain-rmse:0.39689\tvalid-rmse:0.45175\n",
      "[550]\ttrain-rmse:0.39632\tvalid-rmse:0.45174\n",
      "[560]\ttrain-rmse:0.39575\tvalid-rmse:0.45171\n",
      "[570]\ttrain-rmse:0.39514\tvalid-rmse:0.45163\n",
      "[580]\ttrain-rmse:0.39448\tvalid-rmse:0.45162\n",
      "[590]\ttrain-rmse:0.39385\tvalid-rmse:0.45165\n",
      "[600]\ttrain-rmse:0.39327\tvalid-rmse:0.45163\n",
      "[610]\ttrain-rmse:0.39271\tvalid-rmse:0.45164\n",
      "[620]\ttrain-rmse:0.39215\tvalid-rmse:0.45165\n",
      "[630]\ttrain-rmse:0.39161\tvalid-rmse:0.45166\n",
      "[640]\ttrain-rmse:0.39116\tvalid-rmse:0.45163\n",
      "[650]\ttrain-rmse:0.39056\tvalid-rmse:0.45160\n",
      "[660]\ttrain-rmse:0.39001\tvalid-rmse:0.45156\n",
      "[670]\ttrain-rmse:0.38953\tvalid-rmse:0.45157\n",
      "[680]\ttrain-rmse:0.38897\tvalid-rmse:0.45159\n",
      "[690]\ttrain-rmse:0.38846\tvalid-rmse:0.45157\n",
      "[700]\ttrain-rmse:0.38801\tvalid-rmse:0.45162\n",
      "[704]\ttrain-rmse:0.38773\tvalid-rmse:0.45165\n",
      "Fold 4 RMSE: 0.45165\n",
      "Mean: 0.45356\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    \"seed\": 48,\n",
    "    \"max_depth\": 3,\n",
    "    \"eta\": 0.01,  # learning rate\n",
    "    \"gamma\": 0.01,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "#     \"colsample_bytree\": 0.5,\n",
    "#     \"colsample_bylevel\": 0.5,\n",
    "#     \"lambda\": 10,\n",
    "}\n",
    "\n",
    "\n",
    "fold_scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    trn_df = oofs.query(f\"fold != {fold}\")\n",
    "    val_df = oofs.query(f\"fold == {fold}\")\n",
    "\n",
    "    train_dataset = xgb.DMatrix(trn_df[model_folders], label=trn_df[\"target\"])\n",
    "    valid_dataset = xgb.DMatrix(val_df[model_folders], val_df[\"target\"])\n",
    "\n",
    "    num_round = 1000\n",
    "    bst = xgb.train(\n",
    "        param,\n",
    "        train_dataset,\n",
    "        num_round,\n",
    "        evals=[(train_dataset, \"train\"), (valid_dataset, \"valid\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=10,\n",
    "    )\n",
    "    # make prediction\n",
    "    y_pred = bst.predict(valid_dataset)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_pred, val_df[\"target\"]))\n",
    "    print(f\"Fold {fold} RMSE: {rmse:0.5f}\")\n",
    "    fold_scores.append(rmse)\n",
    "\n",
    "print(f\"Mean: {np.mean(fold_scores):0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T23:58:00.917770Z",
     "start_time": "2021-07-28T23:58:00.914399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mean: 0.45378"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('kaggle': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0324064526588904db53d8c1754501a1e17277e16e25f64624bf6abfe73e224f9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
