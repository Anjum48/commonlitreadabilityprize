{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T17:57:34.115120Z",
     "start_time": "2021-05-19T17:57:33.816008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/test.csv\n",
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/sample_submission.csv\n",
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_PATH = Path(f\"/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize\")\n",
    "MODEL_CACHE = Path(\"/mnt/storage/model_cache/torch\")\n",
    "\n",
    "for child in INPUT_PATH.iterdir():\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T17:57:34.165244Z",
     "start_time": "2021-05-19T17:57:34.116924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  standard_error  \n",
       "0  When the young people returned to the ballroom... -0.340259        0.464009  \n",
       "1  All through dinner time, Mrs. Fayre was somewh... -0.315372        0.480805  \n",
       "2  As Roger had predicted, the snow departed as q... -0.580118        0.476676  \n",
       "3  And outside before the palace a great garden w... -1.054013        0.450007  \n",
       "4  Once upon a time there were Three Bears who li...  0.247197        0.510845  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_PATH / \"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T17:57:34.183066Z",
     "start_time": "2021-05-19T17:57:34.166850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2834.000000</td>\n",
       "      <td>2834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.959319</td>\n",
       "      <td>0.491435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.033579</td>\n",
       "      <td>0.034818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.676268</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.690320</td>\n",
       "      <td>0.468543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.912190</td>\n",
       "      <td>0.484721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.202540</td>\n",
       "      <td>0.506268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.649671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  standard_error\n",
       "count  2834.000000     2834.000000\n",
       "mean     -0.959319        0.491435\n",
       "std       1.033579        0.034818\n",
       "min      -3.676268        0.000000\n",
       "25%      -1.690320        0.468543\n",
       "50%      -0.912190        0.484721\n",
       "75%      -0.202540        0.506268\n",
       "max       1.711390        0.649671"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T17:57:34.608213Z",
     "start_time": "2021-05-19T17:57:34.184406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"target\"].hist(bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T17:57:34.613839Z",
     "start_time": "2021-05-19T17:57:34.609950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When the young people returned to the ballroom, it presented a decidedly changed appearance. Instead of an interior scene, it was a winter landscape.\\nThe floor was covered with snow-white canvas, not laid on smoothly, but rumpled over bumps and hillocks, like a real snow field. The numerous palms and evergreens that had decorated the room, were powdered with flour and strewn with tufts of cotton, like snow. Also diamond dust had been lightly sprinkled on them, and glittering crystal icicles hung from the branches.\\nAt each end of the room, on the wall, hung a beautiful bear-skin rug.\\nThese rugs were for prizes, one for the girls and one for the boys. And this was the game.\\nThe girls were gathered at one end of the room and the boys at the other, and one end was called the North Pole, and the other the South Pole. Each player was given a small flag which they were to plant on reaching the Pole.\\nThis would have been an easy matter, but each traveller was obliged to wear snowshoes.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(df.loc[0, \"excerpt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T17:57:34.769019Z",
     "start_time": "2021-05-19T17:57:34.615020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"word_count\"] = df['excerpt'].str.split().apply(len)\n",
    "df[\"word_count\"].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T17:57:35.635744Z",
     "start_time": "2021-05-19T17:57:34.770578Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T18:54:21.806645Z",
     "start_time": "2021-05-19T18:54:17.711318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=MODEL_CACHE)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, cache_dir=MODEL_CACHE)\n",
    "\n",
    "model.classifier.out_proj = torch.nn.Linear(model.classifier.out_proj.in_features, 1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T18:54:24.152856Z",
     "start_time": "2021-05-19T18:54:24.112534Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T18:54:24.938750Z",
     "start_time": "2021-05-19T18:54:24.934779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1054]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"logits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('kaggle': conda)",
   "language": "python",
   "name": "python38164bitkaggleconda0013a04193b845a7a07c668fa6fedcae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
