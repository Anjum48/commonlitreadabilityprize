{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:08:34.965199Z",
     "start_time": "2021-06-08T23:08:34.791686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/mlm_data_val.csv\n",
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/pretrain_text.txt\n",
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/test.csv\n",
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/mlm_data.csv\n",
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/sample_submission.csv\n",
      "/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize/train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_PATH = Path(f\"/mnt/storage_dimm2/kaggle_data/commonlitreadabilityprize\")\n",
    "MODEL_CACHE = Path(\"/mnt/storage/model_cache/torch\")\n",
    "\n",
    "for child in INPUT_PATH.iterdir():\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:08:35.001853Z",
     "start_time": "2021-06-08T23:08:34.966598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  standard_error  \n",
       "0  When the young people returned to the ballroom... -0.340259        0.464009  \n",
       "1  All through dinner time, Mrs. Fayre was somewh... -0.315372        0.480805  \n",
       "2  As Roger had predicted, the snow departed as q... -0.580118        0.476676  \n",
       "3  And outside before the palace a great garden w... -1.054013        0.450007  \n",
       "4  Once upon a time there were Three Bears who li...  0.247197        0.510845  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_PATH / \"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:08:35.014616Z",
     "start_time": "2021-06-08T23:08:35.003467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2834.000000</td>\n",
       "      <td>2834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.959319</td>\n",
       "      <td>0.491435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.033579</td>\n",
       "      <td>0.034818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.676268</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.690320</td>\n",
       "      <td>0.468543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.912190</td>\n",
       "      <td>0.484721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.202540</td>\n",
       "      <td>0.506268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.649671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  standard_error\n",
       "count  2834.000000     2834.000000\n",
       "mean     -0.959319        0.491435\n",
       "std       1.033579        0.034818\n",
       "min      -3.676268        0.000000\n",
       "25%      -1.690320        0.468543\n",
       "50%      -0.912190        0.484721\n",
       "75%      -0.202540        0.506268\n",
       "max       1.711390        0.649671"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:08:35.385575Z",
     "start_time": "2021-06-08T23:08:35.016121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQoklEQVR4nO3dX4xcZ3nH8e/TUELItnGioMU4UZ0LFzVkKWpWgIpUzcogUhLFaUWQUaBOSbVCAooqV4pNpOaismoJpSoq7YVFohiRZkkDKBaINsHVNupFABsinD+EWGCCHWoXsE03RMDC0wuP6eDMendn5uzMPvv93OycPzPnebya375+55wzkZlIkmr5jWEXIEkaPMNdkgoy3CWpIMNdkgoy3CWpoJcNuwCAyy+/PDdu3DjsMgbuhRde4OKLLx52GY2p3h/U77F6f1C7x4MHD/4gM1/VbdtIhPvGjRs5cODAsMsYuNnZWVqt1rDLaEz1/qB+j9X7g9o9RsR3F9rmtIwkFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFTQSV6hKa8HGHV/ouv7I7utXuBKtBY7cJakgw12SCjLcJakgw12SCjLcJakgw12SCjLcJakgw12SCjLcJakgw12SCjLcJakgw12SCjLcJakgw12SClo03CPinog4ERFPdKz7aER8MyK+ERGfi4h1Hdt2RsThiHgmIt7eUN2SpPNYysj9XuC6c9Y9AlyTma8HvgXsBIiIq4GtwOvaz/nniLhgYNVKkpZk0XDPzEeBH52z7uHMnG8vPgZc0X68BZjJzJ9m5neAw8AbB1ivJGkJBjHn/j7gi+3HG4DvdWw72l4nSVpBfX3NXkTcAcwD951d1WW3XOC508A0wPj4OLOzs/2UMpLm5uZK9nVW9f5gsD1un5jvun6Y/4b+DuvqOdwjYhtwA7A5M88G+FHgyo7drgCe7/b8zNwD7AGYnJzMVqvVaykja3Z2lop9nVW9Pxhsj7cu9B2qtwzm9Xvh77CunqZlIuI64Hbgxsz8ScemfcDWiLgwIq4CNgFf6b9MSdJyLDpyj4j7gRZweUQcBe7kzNkxFwKPRATAY5n5/sx8MiIeAJ7izHTNBzLzF00VL0nqbtFwz8x3d1l993n23wXs6qcoaTXbuMD0i7SSvEJVkgoy3CWpIMNdkgoy3CWpIMNdkgoy3CWpIMNdkgrq694y0lrm+ewaZY7cJakgw12SCjLcJakgw12SCvIDVamt2wek2yfmaa18KVLfHLlLUkGGuyQVZLhLUkGGuyQVZLhLUkGGuyQVZLhLUkGGuyQV5EVM0iK8+6NWI0fuklTQouEeEfdExImIeKJj3WUR8UhEPNv+eWnHtp0RcTginomItzdVuCRpYUuZlrkX+DjwyY51O4D9mbk7Ina0l2+PiKuBrcDrgNcAX4qI383MXwy2bOn8zjeVcmT39StYSe8W6mG11K/hWnTknpmPAj86Z/UWYG/78V7gpo71M5n508z8DnAYeONgSpUkLVVk5uI7RWwEPp+Z17SXT2Xmuo7tJzPz0oj4OPBYZn6qvf5u4IuZ+WCX15wGpgHGx8evnZmZGUA7o2Vubo6xsbFhl9GYUe7v0LHTA3md8Yvg+IsDeakFTWy4pOv6hXpYaP9ejPLvcFAq9zg1NXUwMye7bRv02TLRZV3Xvx6ZuQfYAzA5OZmtVmvApQzf7OwsFfs6a5T7u3VAZ7hsn5jnrkMNn1R26IUFNnQ/7pFbWgM79Cj/DgdlLfTYTa9nyxyPiPUA7Z8n2uuPAld27HcF8Hzv5UmSetFruO8DtrUfbwMe6li/NSIujIirgE3AV/orUZK0XIv+fzMi7gdawOURcRS4E9gNPBARtwHPATcDZOaTEfEA8BQwD3zAM2UkaeUtGu6Z+e4FNm1eYP9dwK5+ipIk9cfbD0irjOe/aym8/YAkFWS4S1JBhrskFWS4S1JBfqCqofBDQalZhrtUhH8w1clpGUkqyJG7VjW/Ak/qzpG7JBVkuEtSQU7LaKQ4zSINhiN3SSrIkbsa5Uh8+M73O7j3uotXsBKtJEfuklSQ4S5JBRnuklSQ4S5JBRnuklSQ4S5JBRnuklSQ4S5JBfUV7hHxVxHxZEQ8ERH3R8QrIuKyiHgkIp5t/7x0UMVKkpam53CPiA3AXwKTmXkNcAGwFdgB7M/MTcD+9rIkaQX1e/uBlwEXRcTPgVcCzwM7gVZ7+15gFri9z+NIasChY6e5tcvtCfz2ptUvMrP3J0d8GNgFvAg8nJm3RMSpzFzXsc/JzHzJ1ExETAPTAOPj49fOzMz0XMeompubY2xsbNhlNGYp/R06dnqFqmnG+EVw/MVhV9Gchfqb2HDJyhfTkMrvw6mpqYOZOdltW88j9/Zc+hbgKuAU8K8R8Z6lPj8z9wB7ACYnJ7PVavVaysianZ2lYl9nLaW/bqPC1WT7xDx3Hap7f72F+jtyS2vli2lI9ffhQvr5QPWtwHcy838y8+fAZ4E/BI5HxHqA9s8T/ZcpSVqOfsL9OeDNEfHKiAhgM/A0sA/Y1t5nG/BQfyVKkpar5/9vZuaXI+JB4GvAPPB1zkyzjAEPRMRtnPkDcPMgCpUkLV1fk4mZeSdw5zmrf8qZUbwkaUi8QlWSCjLcJamguud4SerZQt+76sVNq4cjd0kqyHCXpIIMd0kqyHCXpIL8QFXSkvlB6+phuGtZOt/c2yfmf3VjMN/c0mhxWkaSCjLcJakgw12SCjLcJakgw12SCjLcJakgT4VUVwudzyxpdXDkLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkF9XWee0SsAz4BXAMk8D7gGeDTwEbgCPCuzDzZz3HUHM9nl2rq9yKmjwH/lpnvjIiXA68EPgLsz8zdEbED2AHc3udxNOL8I7G2+SUeo6fnaZmI+G3gj4C7ATLzZ5l5CtgC7G3vthe4qb8SJUnLFZnZ2xMj3gDsAZ4Cfh84CHwYOJaZ6zr2O5mZl3Z5/jQwDTA+Pn7tzMxMT3WMsrm5OcbGxoZdxnkdOna65+eOXwTHXxxgMSOoeo9N9zex4ZLmXnyJVsP7sFdTU1MHM3Oy27Z+wn0SeAx4S2Z+OSI+BvwY+NBSwr3T5ORkHjhwoKc6Rtns7CytVmvYZZxXP9Mp2yfmuetQ7dsTVe+x6f4WmpZZyWmc1fA+7FVELBju/ZwtcxQ4mplfbi8/CPwBcDwi1rcPvB440ccxJEk96PlPdmb+d0R8LyJem5nPAJs5M0XzFLAN2N3++dBAKlVf/MBTWlv6/f/Yh4D72mfKfBv4c878b+CBiLgNeA64uc9jSJKWqa9wz8zHgW7zPZv7eV1JUn+8QlWSCjLcJakgw12SCjLcJakgw12SCjLcJakgw12SCjLcJakgw12SCjLcJakgw12SCjLcJakgw12SCjLcJamgut8ftkb5pRySwJG7JJXkyH0VcnQuaTGGu6TGOBAZHqdlJKkgw12SCjLcJakgw12SCuo73CPigoj4ekR8vr18WUQ8EhHPtn9e2n+ZkqTlGMTI/cPA0x3LO4D9mbkJ2N9eliStoL7CPSKuAK4HPtGxeguwt/14L3BTP8eQJC1fZGbvT454EPg74LeAv87MGyLiVGau69jnZGa+ZGomIqaBaYDx8fFrZ2Zmeq5jVM3NzTE2Njbw1z107PTAX7MX4xfB8ReHXUWzqvc4av1NbLhk4K/Z1PtwFExNTR3MzMlu23q+iCkibgBOZObBiGgt9/mZuQfYAzA5OZmt1rJfYuTNzs7SRF+3jsiFIdsn5rnrUO3r4Kr3OGr9HbmlNfDXbOp9OOr6+a2+BbgxIt4BvAL47Yj4FHA8ItZn5vcjYj1wYhCFSpKWruc598zcmZlXZOZGYCvwH5n5HmAfsK292zbgob6rlCQtSxPnue8G3hYRzwJvay9LklbQQCbbMnMWmG0//iGweRCvK0nqjVeoSlJBhrskFWS4S1JBo3OC6xq20BcaHNl9/QpXIqkKR+6SVJDhLkkFGe6SVJDhLkkF+YHqCPOb47XWeHLB4Dhyl6SCDHdJKshpGUkjz+ma5XPkLkkFGe6SVJDTMpJWLadrFubIXZIKMtwlqSDDXZIKcs5dUjmdc/HbJ+a5tb28lubiHblLUkGGuyQVZLhLUkE9z7lHxJXAJ4FXA78E9mTmxyLiMuDTwEbgCPCuzDzZf6mrn3d5lLRS+hm5zwPbM/P3gDcDH4iIq4EdwP7M3ATsby9LklZQz+Gemd/PzK+1H/8v8DSwAdgC7G3vthe4qc8aJUnLFJnZ/4tEbAQeBa4BnsvMdR3bTmbmpV2eMw1MA4yPj187MzPTdx2jZm5ujrGxsV8tHzp2eojVDN74RXD8xWFX0azqPVbvD369x4kNlwy3mAGbmpo6mJmT3bb1He4RMQb8J7ArMz8bEaeWEu6dJicn88CBA33VMYpmZ2dptVq/Wq425759Yp67DtW+VKJ6j9X7g1/vsdp57hGxYLj3dbZMRPwm8Bngvsz8bHv18YhY396+HjjRzzEkScvXc7hHRAB3A09n5t93bNoHbGs/3gY81Ht5kqRe9PP/sbcA7wUORcTj7XUfAXYDD0TEbcBzwM19VbiClnv7UG83KmlU9RzumflfQCyweXOvrytJ6p9XqEpSQYa7JBVU+xyoITk7F995q1FJWkmO3CWpIEfuS1Dt4iNJ9Tlyl6SCDHdJKshpGUlr3vmmXlfrRYmO3CWpIEfuktaMtXRyhCN3SSrIcJekgkpPy3jXRklrVelwl6R+rdZBotMyklRQiZH7cj8BX0ufmEtqxqiP6B25S1JBhrskFWS4S1JBhrskFWS4S1JBJc6WkaRRMSpn0Thyl6SCGgv3iLguIp6JiMMRsaOp40iSXqqRaZmIuAD4J+BtwFHgqxGxLzOfauJ4kjTqVnq6pqmR+xuBw5n57cz8GTADbGnoWJKkc0RmDv5FI94JXJeZf9Fefi/wpsz8YMc+08B0e/G1wDMDL2T4Lgd+MOwiGlS9P6jfY/X+oHaPv5OZr+q2oamzZaLLul/7K5KZe4A9DR1/JETEgcycHHYdTaneH9TvsXp/sDZ67KapaZmjwJUdy1cAzzd0LEnSOZoK968CmyLiqoh4ObAV2NfQsSRJ52hkWiYz5yPig8C/AxcA92Tmk00ca8SVnnaifn9Qv8fq/cHa6PElGvlAVZI0XF6hKkkFGe6SVJDh3qCI+NuI+EZEPB4RD0fEa4Zd06BFxEcj4pvtPj8XEeuGXdMgRcTNEfFkRPwyIkqdTlf9FiERcU9EnIiIJ4ZdyzAY7s36aGa+PjPfAHwe+Jsh19OER4BrMvP1wLeAnUOuZ9CeAP4UeHTYhQxSxy1C/hi4Gnh3RFw93KoG7l7gumEXMSyGe4My88cdixdzzoVcFWTmw5k53158jDPXNJSRmU9nZsWrp8vfIiQzHwV+NOw6hsX7uTcsInYBfwacBqaGXE7T3gd8ethFaEk2AN/rWD4KvGlItagBhnufIuJLwKu7bLojMx/KzDuAOyJiJ/BB4M4VLXAAFuuxvc8dwDxw30rWNghL6a+gRW8RotXNcO9TZr51ibv+C/AFVmG4L9ZjRGwDbgA25yq8cGIZv8NKvEVIcc65NygiNnUs3gh8c1i1NCUirgNuB27MzJ8Mux4tmbcIKc4rVBsUEZ/hzO2Mfwl8F3h/Zh4bblWDFRGHgQuBH7ZXPZaZ7x9iSQMVEX8C/CPwKuAU8Hhmvn2oRQ1IRLwD+Af+/xYhu4Zb0WBFxP1AizO3/D0O3JmZdw+1qBVkuEtSQU7LSFJBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JB/wcF1cFOFbesLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"target\"].hist(bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:08:35.390002Z",
     "start_time": "2021-06-08T23:08:35.386900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When the young people returned to the ballroom, it presented a decidedly changed appearance. Instead of an interior scene, it was a winter landscape.\\nThe floor was covered with snow-white canvas, not laid on smoothly, but rumpled over bumps and hillocks, like a real snow field. The numerous palms and evergreens that had decorated the room, were powdered with flour and strewn with tufts of cotton, like snow. Also diamond dust had been lightly sprinkled on them, and glittering crystal icicles hung from the branches.\\nAt each end of the room, on the wall, hung a beautiful bear-skin rug.\\nThese rugs were for prizes, one for the girls and one for the boys. And this was the game.\\nThe girls were gathered at one end of the room and the boys at the other, and one end was called the North Pole, and the other the South Pole. Each player was given a small flag which they were to plant on reaching the Pole.\\nThis would have been an easy matter, but each traveller was obliged to wear snowshoes.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(df.loc[0, \"excerpt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:08:35.544334Z",
     "start_time": "2021-06-08T23:08:35.390954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"word_count\"] = df['excerpt'].str.split().apply(len)\n",
    "df[\"word_count\"].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:08:35.550427Z",
     "start_time": "2021-06-08T23:08:35.545440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "https://www.africanstorybook.org/                               118\n",
       "https://www.africanstorybook.org/#                               46\n",
       "https://simple.wikipedia.org/wiki/Voltage                         2\n",
       "https://simple.wikipedia.org/wiki/Smelting                        1\n",
       "https://kids.frontiersin.org/article/10.3389/frym.2020.00027      1\n",
       "                                                               ... \n",
       "https://kids.frontiersin.org/article/10.3389/frym.2019.00111      1\n",
       "https://kids.frontiersin.org/article/10.3389/frym.2018.00037      1\n",
       "https://simple.wikipedia.org/wiki/Printing                        1\n",
       "https://kids.frontiersin.org/article/10.3389/frym.2013.00009      1\n",
       "https://simple.wikipedia.org/wiki/Microcontroller                 1\n",
       "Name: url_legal, Length: 667, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"url_legal\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:08:36.553149Z",
     "start_time": "2021-06-08T23:08:35.551996Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/anjum/kaggle/commonlitreadabilityprize/\")\n",
    "\n",
    "from src.tokenizers import SentencePieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.280974Z",
     "start_time": "2021-06-08T23:08:36.554545Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 513M/513M [00:54<00:00, 9.33MB/s] \n",
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BigBirdModel(\n",
       "  (embeddings): BigBirdEmbeddings(\n",
       "    (word_embeddings): Embedding(50358, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(4096, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BigBirdEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BigBirdLayer(\n",
       "        (attention): BigBirdAttention(\n",
       "          (self): BigBirdBlockSparseAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BigBirdSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BigBirdIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BigBirdOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"google/bigbird-roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=MODEL_CACHE)\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name,\n",
    "#     cache_dir=MODEL_CACHE,\n",
    "# #     num_labels=1,\n",
    "# #     output_hidden_states=True,\n",
    "# )\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=MODEL_CACHE,\n",
    "#     num_labels=1,\n",
    "#     output_hidden_states=True,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.457847Z",
     "start_time": "2021-06-08T23:09:36.282214Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 8 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3.Changing attention type to 'original_full'...\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\", return_token_type_ids=True)\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.487319Z",
     "start_time": "2021-06-08T23:09:36.459429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0436,  0.2155,  0.0048,  ..., -0.0037, -0.0745, -0.1550],\n",
       "         [ 0.0622, -0.0671,  0.1194,  ...,  0.2825, -0.1207,  0.0107],\n",
       "         [ 0.2922,  0.1411,  0.2404,  ..., -0.1891, -0.2148, -0.2348],\n",
       "         ...,\n",
       "         [ 0.3144,  0.5579,  0.2185,  ..., -0.0759, -0.3491, -0.2939],\n",
       "         [ 0.2494,  0.2714,  0.2742,  ...,  0.1032,  0.0913, -0.1715],\n",
       "         [ 0.0950,  0.2103, -0.0653,  ..., -0.0927,  0.0104, -0.2929]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[ 0.7159,  0.7797, -0.8079, -0.1930,  0.8439, -0.8236,  0.7879, -0.7916,\n",
       "          0.8415,  0.7366,  0.7378,  0.7608,  0.8238, -0.5347, -0.7968, -0.1178,\n",
       "          0.8261,  0.6708,  0.8290, -0.6996, -0.7915,  0.7902, -0.8807,  0.8601,\n",
       "         -0.1009, -0.8785, -0.8524, -0.7937, -0.6294, -0.6877,  0.7917,  0.7268,\n",
       "          0.7394, -0.7382, -0.7347, -0.8478, -0.7290,  0.6771, -0.8545,  0.7960,\n",
       "         -0.8073,  0.7743,  0.8359, -0.2570,  0.1466,  0.6640, -0.6991,  0.8487,\n",
       "          0.7422,  0.8455,  0.8407,  0.8623,  0.8806,  0.8047, -0.8608,  0.7493,\n",
       "          0.0724, -0.8868,  0.7934,  0.8838,  0.7528,  0.6985, -0.0331, -0.7425,\n",
       "          0.7208, -0.8508,  0.8397, -0.8781, -0.6857,  0.7654, -0.8153,  0.8593,\n",
       "          0.7656, -0.7419,  0.8192,  0.9691,  0.8304,  0.6872, -0.0440,  0.8818,\n",
       "          0.8004, -0.6718, -0.8075,  0.7356, -0.7187,  0.1098,  0.4613,  0.3854,\n",
       "         -0.8472, -0.7318, -0.6923, -0.5853, -0.8271, -0.8516, -0.7315,  0.7580,\n",
       "          0.8436, -0.7311,  0.8522,  0.9777, -0.7362, -0.8487,  0.7977,  0.0731,\n",
       "          0.8953, -0.7272,  0.7611,  0.8419, -0.7514,  0.4516, -0.7686, -0.6072,\n",
       "         -0.9806,  0.7298, -0.6943, -0.8998,  0.8018, -0.8266,  0.3574, -0.7702,\n",
       "         -0.8103,  0.8153, -0.6970,  0.6929, -0.8362, -0.8044, -0.7338, -0.7649,\n",
       "          0.7453, -0.7615, -0.8665, -0.6769,  0.8281,  0.7685, -0.9096, -0.6659,\n",
       "          0.8221, -0.8698,  0.8435,  0.8349,  0.7639, -0.8789,  0.6966,  0.1558,\n",
       "          0.7960,  0.8184,  0.7068,  0.8940, -0.6552, -0.7135,  0.8083, -0.7077,\n",
       "          0.8484, -0.6909, -0.8862, -0.8432, -0.8456,  0.8007,  0.8966, -0.7845,\n",
       "         -0.8256, -0.8583,  0.8610,  0.8533, -0.7736,  0.7864,  0.7369,  0.7521,\n",
       "          0.9687, -0.2788,  0.7842, -0.2816,  0.9040, -0.6822, -0.8121,  0.6372,\n",
       "          0.8168, -0.7055, -0.8494,  0.7323,  0.8975,  0.7616,  0.8389,  0.7545,\n",
       "         -0.8363,  0.7248,  0.8487,  0.7331,  0.7159, -0.8091,  0.8455, -0.7667,\n",
       "         -0.7415,  0.8602, -0.7923, -0.6467,  0.7484, -0.5461, -0.3871, -0.8417,\n",
       "          0.8293, -0.9136,  0.8611, -0.6879, -0.7639,  0.8691,  0.6343, -0.6335,\n",
       "          0.3461, -0.5413,  0.6013, -0.7313,  0.8475, -0.5799, -0.8501,  0.8594,\n",
       "          0.6915, -0.8409,  0.8074,  0.8524, -0.8305, -0.1960,  0.8958,  0.8853,\n",
       "         -0.8037,  0.7613,  0.8067,  0.2556, -0.8131, -0.9094,  0.7742, -0.7345,\n",
       "         -0.8261,  0.6740, -0.7679, -0.8012,  0.7176, -0.7104,  0.7309, -0.6143,\n",
       "         -0.7736,  0.8390,  0.7578,  0.8509,  0.7050,  0.8629,  0.8370, -0.7821,\n",
       "         -0.7389, -0.7371, -0.7893,  0.6538, -0.7302, -0.8032, -0.9591,  0.8932,\n",
       "         -0.7812,  0.7444, -0.7149,  0.9211,  0.7923, -0.7657,  0.9112,  0.8141,\n",
       "          0.8616,  0.8617,  0.8627, -0.7402, -0.7996,  0.8490,  0.7902,  0.6832,\n",
       "          0.0644, -0.2610, -0.8310, -0.6543,  0.5661, -0.1092,  0.6669, -0.8702,\n",
       "         -0.2588, -0.8921, -0.7153,  0.1049, -0.8937, -0.7835,  0.7422, -0.8413,\n",
       "          0.8100,  0.4505,  0.8137, -0.7550, -0.8738,  0.8809, -0.9011, -0.8767,\n",
       "          0.7927, -0.6972, -0.7950,  0.6019, -0.7741,  0.9366, -0.8331, -0.8214,\n",
       "         -0.8345, -0.8336, -0.7513, -0.8770, -0.5622,  0.2992,  0.6998, -0.8573,\n",
       "          0.7878,  0.8163, -0.8210,  0.0312, -0.7562, -0.7611, -0.7609, -0.6460,\n",
       "         -0.7816,  0.8258,  0.8320, -0.7722,  0.8220, -0.7182,  0.7364, -0.8671,\n",
       "         -0.3035,  0.8145,  0.8132,  0.7883, -0.9300,  0.8577,  0.7450, -0.7681,\n",
       "          0.8742,  0.8992, -0.8212, -0.7381, -0.8562,  0.8285,  0.8179, -0.8360,\n",
       "          0.7407,  0.9322, -0.8286,  0.9103, -0.7496,  0.7628, -0.8801, -0.6696,\n",
       "          0.7112, -0.8137, -0.8716,  0.8808, -0.6649, -0.8630, -0.7491,  0.6379,\n",
       "         -0.9346, -0.6361, -0.7673,  0.8626,  0.7605, -0.7457,  0.8255, -0.9008,\n",
       "          0.7905, -0.6637,  0.8527, -0.7455,  0.6260, -0.7268,  0.6887, -0.2978,\n",
       "         -0.8769, -0.8959,  0.6769,  0.7587, -0.7633, -0.8343,  0.6255,  0.7490,\n",
       "         -0.7078, -0.7093, -0.7440,  0.8590,  0.7178,  0.7921,  0.7690, -0.7662,\n",
       "          0.6112, -0.8738,  0.7583,  0.6451, -0.7448,  0.8415,  0.7639,  0.7667,\n",
       "         -0.8544,  0.8539, -0.7443,  0.8508, -0.7603,  0.8193,  0.8897, -0.7455,\n",
       "         -0.6601, -0.8972,  0.8473, -0.7902, -0.7858, -0.7773,  0.7768,  0.8827,\n",
       "          0.7891, -0.7807, -0.8831,  0.8010,  0.6752,  0.7298,  0.7096,  0.8189,\n",
       "          0.8218, -0.8813, -0.8181,  0.0251, -0.7805, -0.6689, -0.8771,  0.8865,\n",
       "          0.7256, -0.7741,  0.7435,  0.7642, -0.9006, -0.8795,  0.7851, -0.7639,\n",
       "         -0.8480, -0.7155,  0.7105, -0.9065,  0.6962,  0.8011, -0.7320,  0.7145,\n",
       "          0.7844,  0.2525, -0.7981, -0.8747, -0.4834,  0.7879,  0.7260,  0.8863,\n",
       "          0.7021,  0.7052, -0.8151,  0.6912, -0.7849,  0.7811,  0.7222,  0.7625,\n",
       "          0.7259, -0.8858,  0.8311, -0.7206,  0.7406,  0.8266, -0.7276, -0.5915,\n",
       "          0.7978,  0.8087,  0.3679, -0.8792, -0.2539, -0.9274,  0.7891,  0.5992,\n",
       "          0.8761, -0.7078,  0.8941, -0.7036, -0.8741, -0.7545,  0.7070,  0.8346,\n",
       "          0.8152, -0.7380,  0.8330, -0.5704,  0.8187,  0.7085,  0.3215, -0.7943,\n",
       "          0.7934,  0.7225,  0.8243,  0.8431, -0.8186,  0.8449,  0.8266,  0.8483,\n",
       "          0.8223,  0.7324,  0.7580,  0.7619, -0.8157,  0.8210,  0.1536,  0.8244,\n",
       "         -0.6985,  0.8285, -0.8654, -0.7276,  0.7499, -0.5436, -0.0855, -0.4063,\n",
       "         -0.8161,  0.7545,  0.8024, -0.7375,  0.2517, -0.8914, -0.8720, -0.3670,\n",
       "          0.2812, -0.3108,  0.7993, -0.8592,  0.8282,  0.7704, -0.6279,  0.8932,\n",
       "         -0.7729,  0.8771,  0.8240,  0.8261,  0.8008,  0.7161,  0.8256, -0.8297,\n",
       "          0.8287,  0.8896,  0.7702,  0.7698, -0.7826,  0.8681, -0.8010,  0.8031,\n",
       "         -0.8393, -0.5516, -0.7394, -0.7234,  0.8057, -0.8173, -0.8641,  0.8322,\n",
       "         -0.8226,  0.8080,  0.8537,  0.7416,  0.7384, -0.7722, -0.6468, -0.7958,\n",
       "         -0.6594, -0.7564, -0.7798, -0.8281, -0.8785, -0.8160, -0.7018,  0.7072,\n",
       "          0.8366,  0.7387, -0.7521, -0.8077,  0.8095, -0.7047,  0.7822,  0.8062,\n",
       "          0.8492, -0.7333, -0.7005, -0.8996,  0.8050,  0.7685,  0.9058, -0.8232,\n",
       "         -0.7625,  0.7351,  0.8058,  0.7104,  0.8940, -0.8056, -0.2118,  0.8139,\n",
       "          0.3762, -0.8645, -0.8407, -0.7255,  0.8069, -0.6724,  0.7793,  0.8907,\n",
       "          0.8110,  0.6416,  0.8113,  0.7257, -0.8839, -0.8241,  0.7179, -0.7274,\n",
       "          0.7641, -0.7372,  0.8011, -0.8707, -0.1121,  0.7926,  0.8382,  0.8435,\n",
       "          0.8375,  0.1676, -0.7384,  0.8198, -0.8327, -0.8093,  0.8459,  0.6602,\n",
       "         -0.8260,  0.7803,  0.7290,  0.3871, -0.8186, -0.7932, -0.7405,  0.7032,\n",
       "          0.8678,  0.7414, -0.8521,  0.7078, -0.7593, -0.7483, -0.7310, -0.8027,\n",
       "         -0.7779,  0.7716,  0.4360, -0.8529, -0.8186, -0.6977, -0.2710, -0.8926,\n",
       "         -0.8806, -0.6924, -0.7043, -0.8007,  0.8536,  0.7958, -0.9117,  0.7479,\n",
       "          0.7312, -0.8346,  0.6583,  0.4898,  0.7751,  0.7598,  0.8305, -0.7468,\n",
       "          0.7621,  0.7050,  0.8176, -0.7435,  0.7743,  0.7896, -0.8390,  0.7541,\n",
       "          0.8220, -0.8709, -0.7863,  0.7492,  0.8037,  0.8010, -0.6533,  0.7089,\n",
       "         -0.6788, -0.7333,  0.8125, -0.6447, -0.8844, -0.7742,  0.7401, -0.5953,\n",
       "          0.9028, -0.7907,  0.8785,  0.8807, -0.8058,  0.7989,  0.7302,  0.7196,\n",
       "         -0.7630, -0.8081, -0.7491,  0.6894,  0.6708,  0.8417, -0.7976, -0.7231,\n",
       "         -0.7731,  0.8352, -0.8539, -0.7319, -0.8413,  0.7388,  0.8248, -0.8206,\n",
       "          0.7046,  0.9132, -0.9014,  0.7661,  0.7795, -0.8423,  0.8183,  0.8354,\n",
       "         -0.8410,  0.8011, -0.6976,  0.8009,  0.7152,  0.8340,  0.7037,  0.7525,\n",
       "          0.7327,  0.7254, -0.8369, -0.1928,  0.6860, -0.0477,  0.9746, -0.9348,\n",
       "         -0.7925,  0.8256,  0.8400,  0.4468,  0.8085,  0.6525,  0.7901, -0.8513,\n",
       "         -0.9546, -0.7483, -0.8069,  0.8332,  0.7843,  0.1191,  0.7351, -0.8158,\n",
       "          0.7503,  0.7545,  0.7558,  0.7187,  0.8955,  0.9119, -0.2931, -0.8183]],\n",
       "       grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs  #[\"logits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.492111Z",
     "start_time": "2021-06-08T23:09:36.488559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   65, 18536,   112,   717,  3391,   419, 13880,    66]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.496467Z",
     "start_time": "2021-06-08T23:09:36.493355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.515043Z",
     "start_time": "2021-06-08T23:09:36.497711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.weight\n",
      "pooler.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.518664Z",
     "start_time": "2021-06-08T23:09:36.516262Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-e5c9403477cf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-e5c9403477cf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.519824Z",
     "start_time": "2021-06-08T23:08:34.814Z"
    }
   },
   "outputs": [],
   "source": [
    "model.roberta.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T23:09:36.520576Z",
     "start_time": "2021-06-08T23:08:34.816Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_params = [param for name, param in model.named_parameters() if name.startswith(\"classifier\")]\n",
    "clf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('kaggle': conda)",
   "language": "python",
   "name": "python38164bitkaggleconda0013a04193b845a7a07c668fa6fedcae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
